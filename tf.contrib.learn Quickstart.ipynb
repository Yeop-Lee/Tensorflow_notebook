{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.contrib.learn Quickstart\n",
    "\n",
    "TensorFlow’s high-level machine learning API (tf.contrib.learn) makes it easy to configure, train, and evaluate a variety of machine learning models. In this quickstart tutorial, you’ll use tf.contrib.learn to construct a neural network classifier and train it on Fisher’s Iris data set to predict flower species based on sepal/petal geometry. You’ll perform the following five steps:\n",
    "\n",
    "1. Load CSVs containing Iris training/test data into a TensorFlow Dataset\n",
    "2. Construct a neural network classifier\n",
    "3. Fit the model using the training data\n",
    "4. Evaluate the accuracy of the model\n",
    "5. Classify new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 4), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966667\n",
      "Predictions: [1 2]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#data sets\n",
    "IRIS_TRAINING = \"data/iris_training.csv\"\n",
    "IRIS_TEST = \"data/iris_test.csv\"\n",
    "\n",
    "#Load datasets\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv(filename = IRIS_TRAINING, \n",
    "                                                       target_dtype = np.int)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv(filename = IRIS_TEST, \n",
    "                                                   target_dtype = np.int)\n",
    "\n",
    "#Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\",dimension = 4)]\n",
    "\n",
    "#Build 3 layer DNN with 10, 20, 10 units respectively\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns = feature_columns,\n",
    "                                           hidden_units  = [10,20,10],\n",
    "                                           n_classes = 3,\n",
    "                                           model_dir=\"/tmp/iris_model\")\n",
    "\n",
    "#Fit model\n",
    "classifier.fit(x=training_set.data,\n",
    "              y=training_set.target,\n",
    "              steps = 2000)\n",
    "\n",
    "#Evaluate accuracy\n",
    "accuracy_score = classifier.evaluate(x=test_set.data,\n",
    "                                    y=test_set.target)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    "\n",
    "#Classify two new flower samples.\n",
    "new_samples = np.array([[6.4,3.2,4.5,1.5],[5.8,3.1,5.0,1.7]],dtype = float)\n",
    "y= classifier.predict(new_samples)\n",
    "print('Predictions: {}'.format(str(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Iris 데이터 CSV 파일을 텐서플로우로 불러오기\n",
    "\n",
    "Iris 데이터셋은 Iris 종 내에서 서로 연관된 Iris setosa, Iris virginica, and Iris versicolor 세 종이 각각 50개씩의 표본으로 구성되어 150개 행의 데이터로 되어있습니다. 각각의 행은 각 꽃의 표본에 대한 다음의 정보를 담고 있습니다 : 꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비, 그리고 꽃의 종류. 꽃의 종류는 정수로 표현\n",
    "0 : Iris setosa , 1: Iris versicolor , 2: Iris virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이 튜토리얼을 위해서는 Iris data는 임의적으로 섞인 후에, 두 개의 따로 떨어진 CSV 파일로 나누어져야 합니다. 이는 120개의 표본을 갖는 훈련 데이터(iris_training.csv)와 30개의 표본을 갖는 테스트 데이터(iris_test.csv)입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "시작하기 위해선, 먼저 텐서플로우와 numpy를 불러옵니다<br>\n",
    "그 다음, learn.datasets.base에 있는 load_csv() 함수를 이용하여 훈련 셋과 테스트 셋을 Dataset으로 불러옵니다. \n",
    "\n",
    "load_csv() 함수는 두 개의 인자를 요구합니다.\n",
    "\n",
    "1. filename, CSV 파일이 존재하는 파일의 경로\n",
    "2. target_dtype, dataset의 목표 값의 numpy 데이터형\n",
    "\n",
    "여기에서 목표 값(모델을 훈련시켜 예측하려고 하는 값)은 0–2의 정수로 구성된 꽃의 종입니다. 따라서, 적절한 numpy 데이터형은 np.int입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "IRIS_TRAINING = \"data/iris_training.csv\"\n",
    "IRIS_TEST = \"data/iris_test.csv\"\n",
    "\n",
    "# 데이터셋을 불러옵니다.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TRAINING, target_dtype=np.int)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv(filename=IRIS_TEST, target_dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음, 길이 및 너비 등의 특성 데이터와 목표 값에 변수를 할당합니다.<br> 훈련 데이터셋의 특성 데이터는 x_train, 테스트 데이터셋의 특성 데이터는 x_test, 훈련 데이터셋의 목표 값은 y_train, 테스트 데이터셋의 목표 값은 y_test입니다.<br> tf.contrib.learn의 Dataset은 named tuples이며, 순차적으로 데이터와 목표 필드(역주 : namedtuple의 field_name을 말합니다)를 통해 특성 데이터와 목표 값에 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = training_set.data, test_set.data, \\\n",
    "  training_set.target, test_set.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후술할 “Iris 훈련 데이터로 DNNClassifier 피팅하기”에서, x_train과 y_train을 이용하여 모델을 훈련시키고, “모델 정확도 평가하기”에서는 x_test와 y_test를 이용할 것입니다. 하지만 먼저, 다음 문단에선 모델을 구성해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥 인공신경망 분류기 만들기\n",
    "\n",
    "tf.contrib.learn은 데이터로 훈련과 평가를 실행할 수 있도록 곧장 사용할 수 있는, Estimator라 불리는 여러 가지의 미리 정의된 모델을 제공합니다. 여기에서는 Iris data를 피팅하기 위해 딥 인공 신경망 모델을 설정하도록 합시다. tf.contrib.learn을 이용하면, DNNClassifier를 한 줄 만에 인스턴스화할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: `feature_columns` will be required after 2016-08-01.\n",
      "Instructions for updating:\n",
      "Pass `tf.contrib.learn.infer_real_valued_columns_from_input(x)` or `tf.contrib.learn.infer_real_valued_columns_from_input_fn(input_fn)` as `feature_columns`, where `x` or `input_fn` is your argument to `fit`, `evaluate`, or `predict`.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpN7OYsR\n"
     ]
    }
   ],
   "source": [
    "# 10-20-10의 구조를 갖는 3층 DNN를 만듭니다\n",
    "classifier = tf.contrib.learn.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드는 각각 10, 20, 10개의 뉴런으로 이루어진 3개의 은닉층을 포함한 DNNClassifier 모델을 생성합니다. 이는 (hidden_units=[10, 20, 10]), 그리고 세 개의 목표 분류 (n_classes=3)에 순차적으로 따른 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris 훈련 데이터로 DNNClassifier 피팅하기\n",
    "\n",
    "이제 DNN classifier 모델을 설정했으니, fit 메소드를 이용하여 Iris 훈련 데이터로 이를 피팅할 수 있습니다. 특성 데이터(x_train)와 목표 값(y_train), 그리고 train할 단계 수(여기서는 200) 인자로 넘겨줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(hidden_units=[10, 20, 10], dropout=None, optimizer=None, feature_columns=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "classifier.fit(x=x_train, y=y_train, steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier에서 모델의 상태는 유지됩니다. 이는, 만약 원한다면 모델을 반복하여 학습시킬 수 있다는 것을 의미합니다. 예를 들어서, 위의 한 줄은 다음의 두 줄과 완벽하게 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 4), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(hidden_units=[10, 20, 10], dropout=None, optimizer=None, feature_columns=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x=x_train, y=y_train, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 만약 학습되는 동안에 모델을 추적하고 싶은 것이라면, (위와 같은 두 줄) 대신에 로그를 남기기 위해서 텐서플로우의 monitor를 사용하는 게 낫습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정확도 평가하기\n",
    "\n",
    "이제 Iris 테스트 데이터에 맞춰 DNNClassifier 모델을 피팅했습니다. 이제, evaluate 메소드를 이용하여 Iris 테스트 데이터로 모델의 정확도를 확인해볼 수 있습니다. evaluate는 fit과 같이 특성 데이터와 목표 값을 인자로 건내받고, 평가 결과로서 dict를 반환합니다. 다음의 코드는 Iris 테스트 데이터—x_test와 y_test—를 건내받아, 결과값으로 accuracy를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 4), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966667\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = classifier.evaluate(x=x_test, y=y_test)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 표본 분류하기\n",
    "\n",
    "새로운 표본을 분류하기 위해 estimator의 predict() 메소드를 이용합시다. 예를 들어, 다음의 두 가지 새로운 꽃의 표본이 있다고 해봅시다 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 2]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 두 꽃의 표본을 분류합니다.\n",
    "new_samples = np.array(\n",
    "    [[6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]], dtype=float)\n",
    "y = classifier.predict(new_samples)\n",
    "print ('Predictions: {}'.format(str(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() 메소드는 각 표본의 예측 결과를 하나씩 배열로 반환합니다. <br>따라서 모델은 첫 번째 표본을 Iris versicolor, 두 번째 표본을 Iris virginica로 예측하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가적인 자료\n",
    "\n",
    "tf.contrib.learn에 대해 추가적인 참고 자료를 원한다면, 공식적인 API docs를 살펴보십시오.\n",
    "선형 모델을 생성하기 위해서 tf.contrib.learn을 이용하는 것에 대해 좀 더 배우기 위해선 Large-scale Linear Models with TensorFlow를 살펴보십시오.\n",
    "브라우저에서의 신경망 모델링과 시각화를 체험해보기 위해선, Deep Playground를 살펴보십시오.\n",
    "신경망에 대한 좀 더 심화된 튜토리얼을 원한다면 Convolutional Neural Networks와 Recurrent Neural Networks를 살펴보십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
