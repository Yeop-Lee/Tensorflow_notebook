{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Name setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##tr 0 to 3 is location value\n",
    "filename0_tr = \"wifi_ET_0_1472570446\"\n",
    "filename1_tr = \"wifi_ET_1_1472593839\"\n",
    "filename2_tr = \"wifi_ET_2_1472598476\"\n",
    "filename3_tr = \"wifi_ET_3_1472590170\"\n",
    "\n",
    "filename0_tr1 = \"wifi_ET_0_1420114448\"\n",
    "filename1_tr1 = \"wifi_ET_1_1420137839\"\n",
    "filename2_tr1 = \"wifi_ET_2_1420142476\"\n",
    "filename3_tr1 = \"wifi_ET_3_1420134169\"\n",
    "\n",
    "filename0_tr2 = \"wifi_ET_0_1420090965\"\n",
    "filename1_tr2 = \"wifi_ET_1_1420098884\"\n",
    "filename2_tr2 = \"wifi_ET_2_1420095231\"\n",
    "filename3_tr2 = \"wifi_ET_3_1420108956\"\n",
    "\n",
    "filename0 = \"5Act_Var_Te1_JH_Wifi_raw_complete\"\n",
    "filename1 = \"5Act_Var_Te2_JH_Wifi_raw_complete\"\n",
    "filename2 = \"5Act_Var_Tr1_JH_Wifi_raw_complete\"\n",
    "filename3 = \"5Act_Var_Tr2_JH_Wifi_raw_complete\"\n",
    "\n",
    "\n",
    "##te 0 to 3 is location value\n",
    "filename0_te = \"wifi_ET_0_1472546966\"\n",
    "filename1_te = \"wifi_ET_1_1472554884\"\n",
    "filename2_te = \"wifi_ET_2_1472551231\"\n",
    "filename3_te = \"wifi_ET_3_1472564959\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_step = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = []\n",
    "\n",
    "ap_address = []\n",
    "ap_signal = []\n",
    "\n",
    "bi_location = []\n",
    "ap_lev = []\n",
    "ap_lev_times = []\n",
    "selected_ap = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file은 한번 만 읽어서 각 array에 저장한 후에 처리하도록 함(같은 파일을 다시 읽지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename,ap_address, ap_signal, location):\n",
    "    filename = \"data/wifi_et/\"+filename+\".csv\"\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        reader = csv.reader (csvfile, delimiter = ',')\n",
    "        for row in reader:\n",
    "            ap_address.append(row[2])\n",
    "            ap_signal.append(row[3])\n",
    "            location.append(row[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 ap_address 들을 구해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ap_lev(ap_address,ap_lev):\n",
    "    for i in range(0,len(ap_address)):\n",
    "        if ap_address[i] not in ap_lev:\n",
    "            ap_lev.append(ap_address[i])\n",
    "    return ap_lev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 ap가 총 몇 회 불렸는지 확인하는 함수 해당 함수는 get_ap_lev 함수 실행 이후에 돌려야함\n",
    "count함수와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ap_levtimes(ap_address,ap_lev,ap_lev_times):\n",
    "    ap_lev_times = np.zeros(len(ap_lev),dtype=np.int)\n",
    "    for i in range(0, len(ap_address)):\n",
    "        index = ap_lev.index(ap_address[i])\n",
    "        ap_lev_times[index] += 1\n",
    "    return ap_lev_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ap_signal의 등장횟수가 많은 것을 기준으로 NN에 이용할 AP를 선택하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_ap_address(data_max,ap_lev, ap_lev_times, selected_ap):\n",
    "    selected_ap_index = []\n",
    "    threshold = data_max *0.90\n",
    "    for i in range(0,len(ap_lev_times)):\n",
    "        if ap_lev_times[i] >= threshold:\n",
    "            selected_ap_index.append(i)\n",
    "    for i in range(0, len(selected_ap_index)):\n",
    "        selected_ap.append(ap_lev[selected_ap_index[i]])\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data의 수가 가장 많은 것을 기준으로, 해당 data의 등장후 다음 등장 이전까지를 하나의 epoch으로 지정\n",
    "\n",
    "위의 흐름대로 진행할 때 데이터 중에서 다른 location 데이터와 함께 들어와 있는 경우, \n",
    "무조건 행에 따라서 data를 나열하면 input(ap_signal)과 output(location)에 혼선이 있을 우려가 있음\n",
    "\n",
    "[0 1 2 0 1 2 0 1] 로 등장하였다고 가정하고, 해당 하는 location 이<br>[5 5 5 5 5 5 5 4] 로 등장하였을 경우, \n",
    "\n",
    "마지막 두 개의 ap_address_index에서 0 1 이 다른 location인 경우가 발생되는 것을 방지하고자 함\n",
    "\n",
    "우선 (location 별로 partition을 생성한 다음)==>raw data는 원래 떨어져 있으므로, 이것을 기준으로 다시 짜도록함.\n",
    "\n",
    "각 파티션 별로 ap selected array를 구현한 다음 다시 합쳐지는 방식을 이용함\n",
    "\n",
    "\n",
    "1. (선택된 ap index) x (data_max) 행렬\n",
    "2. (location) x (data_max) 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 함수는 selected_ap_signal의 갯수가 4개임을 알고서 하는 것.\n",
    "\n",
    "수정이 요구되나,<br>\n",
    "4개만 있어도 결과값이 잘 나온다면 애초에 셀렉트할때 4개만 해도 무방할 것이라고 판단됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_selected_ap_array(ap_address,ap_signal,selected_ap,location, data_max):\n",
    "    j = -1\n",
    "    converted_ap_signal = np.zeros((data_max, len(selected_ap)))\n",
    "    converted_location = []\n",
    "    for i in range(0,len(ap_signal)):\n",
    "        if ap_address[i] == selected_ap[0]:\n",
    "            j = j+1\n",
    "            converted_ap_signal[j][0] = ap_signal[i]\n",
    "            converted_location.append(location[i])\n",
    "        elif ap_address[i] == selected_ap[1]:\n",
    "            converted_ap_signal[j][1] = ap_signal[i]\n",
    "        elif ap_address[i] == selected_ap[2]:\n",
    "            converted_ap_signal[j][2] = ap_signal[i]\n",
    "        elif ap_address[i] == selected_ap[3]:\n",
    "            converted_ap_signal[j][3] = ap_signal[i]\n",
    "        else :\n",
    "            continue\n",
    "    return converted_ap_signal, converted_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "location을 softmax함수에 이용할 수 있도록 변환 <br>\n",
    "1 => [0,1,0,0]<br>\n",
    "3 => [0,0,0,1] 식으로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_location_to_binary_array(data_max,location):\n",
    "    if data_max != len(location):\n",
    "        print \"Miss matched!\"\n",
    "        print data_max + \"!=\" + len(location)\n",
    "        return \n",
    "    \n",
    "    location_num = int(location[np.argmax(location)])\n",
    "    bi_location = np.zeros((data_max,location_num+1), dtype = int)\n",
    "    for i in range(0,data_max):\n",
    "        bi_location[i,location[i]] = 1\n",
    "    return bi_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight, bias 생성 함수 y = wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================Function End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data pre_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ap의 level과 총 level갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "read_file(filename0_tr,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr1,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr2,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0,ap_address, ap_signal, location)\n",
    "read_file(filename1,ap_address, ap_signal, location)\n",
    "read_file(filename2,ap_address, ap_signal, location)\n",
    "read_file(filename3,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr1,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr2,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0,ap_address, ap_signal, location)\n",
    "read_file(filename1,ap_address, ap_signal, location)\n",
    "read_file(filename2,ap_address, ap_signal, location)\n",
    "read_file(filename3,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr1,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr1,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename1_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename2_tr2,ap_address, ap_signal, location)\n",
    "read_file(filename3_tr2,ap_address, ap_signal, location)\n",
    "\n",
    "read_file(filename0,ap_address, ap_signal, location)\n",
    "read_file(filename1,ap_address, ap_signal, location)\n",
    "read_file(filename2,ap_address, ap_signal, location)\n",
    "read_file(filename3,ap_address, ap_signal, location)\n",
    "\n",
    "\n",
    "get_ap_lev(ap_address,ap_lev)\n",
    "ap_lev_times = get_ap_levtimes(ap_address,ap_lev,ap_lev_times)\n",
    "data_max = ap_lev_times[np.argmax(ap_lev_times)]\n",
    "threshold = select_ap_address(data_max,ap_lev, ap_lev_times, selected_ap)\n",
    "converted_ap_signal, converted_location = convert_to_selected_ap_array(ap_address,ap_signal,selected_ap,location, data_max)\n",
    "bi_location = make_location_to_binary_array(data_max, converted_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print training values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00:26:66:d0:c4:dc', '00:27:1c:ea:40:af', '00:23:aa:3d:d9:41', '00:27:1c:08:41:16', '00:01:36:2d:ea:4c', '00:40:5a:db:5e:c9', '08:5d:dd:71:40:b4', '00:07:89:36:e2:ba', '90:9f:33:40:a0:9e', '64:e5:99:6a:ec:24', '00:30:0d:62:4c:24', '00:26:66:78:99:a8', '00:27:1c:3b:0a:53', '00:23:aa:3c:7a:c1', '90:9f:33:f5:73:cc', '00:26:66:76:37:9c', '08:5d:dd:48:92:27', '04:8d:39:36:e5:9d', '08:5d:dd:89:c1:93', 'c8:3a:35:05:ae:e0', '90:9f:33:a5:15:82', '90:9f:33:6d:8e:b6', '00:08:9f:16:28:42', '90:9f:33:8f:a2:6a', '64:e5:99:82:5a:21', '90:9f:33:bd:f5:4c', '00:26:66:a0:18:ee', '08:5d:dd:2d:a4:a8', '90:9f:33:6c:a4:92', '00:07:89:2b:53:35', '08:5d:dd:0b:0a:3a', 'ec:08:6b:e0:fa:ee', '00:27:1c:23:20:6e', '00:27:1c:23:20:6d', '04:8d:38:95:b3:f5', '00:26:66:f4:d0:58', '00:07:89:3f:fc:28', '08:5d:dd:43:8e:ef', '90:9f:33:19:82:2e', '08:5d:dd:11:39:20', '00:07:89:17:22:1f', '00:30:0d:15:7c:30', '08:5d:dd:0a:30:6a', '90:9f:33:8f:f5:08', '90:9f:33:3d:3d:4a', '00:30:0d:a9:f7:1e', '10:f9:6f:f4:4c:69', '10:f9:6f:f4:4c:6a', '00:08:9f:92:40:d8', '64:e5:99:bb:01:12', 'f0:b4:29:1a:62:6d', '00:08:52:21:1b:4c', '00:40:5a:c1:28:62', '00:40:5a:c1:28:61', '90:9f:33:40:4a:02', '00:08:9f:40:0b:6f', '90:9f:33:6c:cb:9e', '9c:d6:43:af:41:d4', 'c0:a0:bb:59:a6:b8', '00:07:89:46:79:45', '18:53:e0:01:49:bd', '00:26:66:f4:06:20', '18:53:e0:01:49:be', '00:26:66:5c:da:a4', '90:9f:33:92:73:54', 'bc:96:80:98:67:04', '08:5d:dd:46:49:3a', '00:17:c3:9f:b6:1d', 'bc:96:80:98:67:01', '00:08:52:36:2d:43', '64:e5:99:e1:a5:1a', '08:5d:dd:33:d2:a1', '00:27:1c:53:50:ba', '10:68:3f:48:bf:5d', '00:f4:6f:96:a9:c5', '00:08:52:37:5e:2c', '04:8d:38:3d:a4:74', '00:30:0d:c1:8f:c1', '00:07:89:17:f6:c2', '00:e0:4c:81:86:86', '08:5d:dd:82:d1:9f', '4c:e6:76:31:50:18', '4c:e6:76:31:50:1c', '00:40:5a:cf:ff:49', '00:07:89:1f:d0:58', '00:17:c3:ae:42:73', '00:08:5b:4e:cc:b1', 'ac:a2:13:54:06:98', '04:8d:38:19:3d:bc', '00:40:5a:59:bf:49', '00:08:52:25:75:3e', 'b8:8d:12:61:0d:33', '00:40:5a:68:7a:11']\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "print get_ap_lev(ap_address, ap_lev)\n",
    "print len(ap_lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13074 12939  5769 12729 12948   738  3381   711  1083   339  2334   723\n",
      "   207    36   471  5124    12  1215   555   177   126   369   294   573\n",
      "   387   138   102    60     6    12    12     3    12     6     6  3246\n",
      "  3246  1731  2721  2199  1269  1191  1737  2388   330  1272   960   594\n",
      "   831   756   840   693   588   828   666   417   342   354    99   261\n",
      "    96    69    60    21   225   195    57    72   237    75    54    18\n",
      "     6  1515  1275   828    87   258   132    33    90    24    39    30\n",
      "    12    78     6    45     6    12     6     6     6]\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "print ap_lev_times\n",
    "print len(ap_lev_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11766.6\n",
      "['00:26:66:d0:c4:dc', '00:27:1c:ea:40:af', '00:27:1c:08:41:16', '00:01:36:2d:ea:4c']\n"
     ]
    }
   ],
   "source": [
    "print threshold\n",
    "print selected_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13074\n"
     ]
    }
   ],
   "source": [
    "print len(converted_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-56. -53. -76. -81.]\n",
      " [-54. -55. -76. -88.]\n",
      " [-56. -55. -74. -87.]\n",
      " ..., \n",
      " [-60. -83. -82. -83.]\n",
      " [-64. -80. -82. -82.]\n",
      " [-63. -84. -76. -83.]]\n"
     ]
    }
   ],
   "source": [
    "print converted_ap_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ..., \n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print bi_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_x = converted_ap_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_y = bi_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location0 = []\n",
    "location1 = []\n",
    "location2 = []\n",
    "location3 = []\n",
    "ap_signal = []\n",
    "ap_address = []\n",
    "location = []\n",
    "ap_lev = []\n",
    "ap_lev_times = []\n",
    "data_max = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_file(filename0_te,ap_address, ap_signal, location0)\n",
    "read_file(filename1_te,ap_address, ap_signal, location1)\n",
    "read_file(filename2_te,ap_address, ap_signal, location2)\n",
    "read_file(filename3_te,ap_address, ap_signal, location3)\n",
    "location = location0 + location1+ location2 + location3\n",
    "\n",
    "get_ap_lev(ap_address,ap_lev)\n",
    "ap_lev_times = get_ap_levtimes(ap_address,ap_lev,ap_lev_times)\n",
    "data_max = ap_lev_times[np.argmax(ap_lev_times)]\n",
    "converted_ap_signal, converted_location = convert_to_selected_ap_array(ap_address,ap_signal,selected_ap,location, data_max)\n",
    "bi_location = make_location_to_binary_array(data_max, converted_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-48. -59. -59. -66.]\n",
      " [-49. -59. -60. -73.]\n",
      " [-50. -60. -60. -73.]\n",
      " ..., \n",
      " [-65. -84. -92. -83.]\n",
      " [-67. -86. -89. -87.]\n",
      " [-65. -76. -92. -87.]]\n"
     ]
    }
   ],
   "source": [
    "print converted_ap_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ..., \n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print bi_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te_x = converted_ap_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te_y = bi_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00:26:66:d0:c4:dc', '00:27:1c:ea:40:af', '00:27:1c:08:41:16', '00:01:36:2d:ea:4c']\n",
      "1431\n"
     ]
    }
   ],
   "source": [
    "print selected_ap\n",
    "print data_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network algorithm : 2 hidden layer, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_num = int(location[np.argmax(location)]) + 1 # 0, 1, 2, 3\n",
    "selected_num = len(selected_ap)\n",
    "hidden_dim = selected_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print location_num\n",
    "print selected_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = weight_variable([selected_num, hidden_dim])\n",
    "b = bias_variable([hidden_dim])\n",
    "\n",
    "W2 = weight_variable([hidden_dim,location_num])\n",
    "b2 = bias_variable([location_num])\n",
    "\n",
    "X = tf.placeholder(\"float\",[None, selected_num])\n",
    "Y = tf.placeholder(\"float\",[None,location_num])\n",
    "\n",
    "hidden = tf.nn.relu(tf.matmul(X, W)+b)\n",
    "sfmax = tf.nn.softmax(tf.matmul(hidden,W2)+b2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(sfmax),reduction_indices=[1]))\n",
    "train = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)#AdagradOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.257862\n",
      "0.2942\n",
      "0.2942\n",
      "0.2942\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b9fd6e196cab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcorrect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msfmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    598\u001b[0m           \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[1;32m--> 600\u001b[1;33m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[0;32m    601\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for step in range(training_step):\n",
    "    result = sess.run(train, feed_dict = {X: tr_x, Y: tr_y})\n",
    "    correct_prediction = tf.equal(tf.argmax(sfmax,1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    if step%1000 == 0:\n",
    "        print sess.run(accuracy,feed_dict = {X: te_x, Y: te_y})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
