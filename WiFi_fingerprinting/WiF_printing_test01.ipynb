{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = 20\n",
    "location_num = 4\n",
    "training_step = 100\n",
    "\n",
    "##tr\n",
    "filename0_tr = \"wifi_ET_0_1472570446\"\n",
    "filename1_tr = \"wifi_ET_1_1472593839\"\n",
    "filename2_tr = \"wifi_ET_2_1472598476\"\n",
    "filename3_tr = \"wifi_ET_3_1472590170\"\n",
    "\n",
    "##te\n",
    "filename0_te = \"wifi_ET_0_1472546966\"\n",
    "filename1_te = \"wifi_ET_1_1472554884\"\n",
    "filename2_te = \"wifi_ET_2_1472551231\"\n",
    "filename3_te = \"wifi_ET_3_1472564959\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_ndarray(list):\n",
    "    lgt = len(list)\n",
    "    x = np.zeros((1,lgt),dtype ='float')\n",
    "    for i in range(0,lgt):\n",
    "        x[0,i]=list[i]\n",
    "    return x\n",
    "\n",
    "def to_y_binary_array(list, location_num):\n",
    "    lgt = len(list)\n",
    "    out_list = np.zeros((lgt, location_num))\n",
    "    for i in range(0,lgt):\n",
    "        if list[i] == '0':\n",
    "            out_list[i,0] = 1\n",
    "        elif list[i] == '1' :\n",
    "            out_list[i,1]=1\n",
    "        elif list[i] == '2' :\n",
    "            out_list[i,2] = 1\n",
    "        else :\n",
    "            out_list[i,3] = 1\n",
    "    return out_list\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_wifi_data(filename,signal,location,address_index):\n",
    "    filename = \"data/wifi_et/\"+filename+\".csv\"\n",
    "    with open (filename,'rb') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = ',')\n",
    "        for row in reader:\n",
    "            signal.append(row[3])\n",
    "            location.append(row[4])\n",
    "            if row[2] not in address_index:\n",
    "                address_index.append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal_tr = []\n",
    "location_tr = []\n",
    "address_index_tr = []\n",
    "\n",
    "signal_te = []\n",
    "location_te = []\n",
    "address_index_te = []\n",
    "\n",
    "read_wifi_data(filename0_tr,signal_tr,location_tr, address_index_tr)\n",
    "read_wifi_data(filename1_tr,signal_tr,location_tr, address_index_tr)\n",
    "read_wifi_data(filename2_tr,signal_tr,location_tr, address_index_tr)\n",
    "read_wifi_data(filename3_tr,signal_tr,location_tr, address_index_tr)\n",
    "\n",
    "read_wifi_data(filename0_te,signal_te,location_te, address_index_te)\n",
    "read_wifi_data(filename1_te,signal_te,location_te, address_index_te)\n",
    "read_wifi_data(filename2_te,signal_te,location_te, address_index_te)\n",
    "read_wifi_data(filename3_te,signal_te,location_te, address_index_te)\n",
    "\n",
    "tr_data_num = len(signal_tr)\n",
    "te_data_num = len(signal_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-56. -53. -72. ..., -88. -89. -89.]] [[ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]] [[-48. -59. -59. ..., -89. -92. -96.]] [[ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "tr_x = to_ndarray(signal_tr)\n",
    "tr_y = to_y_binary_array(location_tr,location_num)\n",
    "\n",
    "te_x = to_ndarray(signal_te)\n",
    "te_y = to_y_binary_array(location_te,location_num)\n",
    "\n",
    "print tr_x, tr_y, te_x , te_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = weight_variable([1,hidden_dim])\n",
    "b = bias_variable([hidden_dim])\n",
    "\n",
    "W2 = weight_variable([hidden_dim,location_num])\n",
    "b2 = bias_variable([location_num])\n",
    "\n",
    "X = tf.placeholder(\"float\",[None,1])\n",
    "Y = tf.placeholder(\"float\",[None,location_num])\n",
    "\n",
    "hidden = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "sfmax = tf.nn.softmax(tf.matmul(hidden,W2)+b2)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(Y*tf.log(sfmax))\n",
    "train = tf.train.AdamOptimizer(1e-2).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9041 8479\n"
     ]
    }
   ],
   "source": [
    "print tr_data_num,te_data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.216417\n",
      "0.216417\n",
      "0.207454\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n",
      "0.382238\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "start_time = time.time()\n",
    "for step in xrange(training_step):\n",
    "    tr_x = np.reshape(tr_x,(-1,1))\n",
    "    tr_y = np.reshape(tr_y,(-1,location_num))\n",
    "    te_x = np.reshape(te_x,(-1,1))\n",
    "    sess.run(train, feed_dict = {X: tr_x, Y: tr_y})\n",
    "    correct_prediction = tf.equal(tf.argmax(sfmax,1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print sess.run(accuracy,feed_dict = {X: te_x, Y: te_y})\n",
    "        \n",
    "excute_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-56.]\n",
      " [-53.]\n",
      " [-72.]\n",
      " ..., \n",
      " [-88.]\n",
      " [-89.]\n",
      " [-89.]] [[ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print tr_x, tr_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31923771  0.2518827   0.19638392  0.23249562]\n",
      " [ 0.32671326  0.2576901   0.18343385  0.23216276]\n",
      " [ 0.32671326  0.2576901   0.18343385  0.23216276]\n",
      " ..., \n",
      " [ 0.33784503  0.26632494  0.16470551  0.23112452]\n",
      " [ 0.34966886  0.27547792  0.14558315  0.22927   ]\n",
      " [ 0.35027304  0.27594504  0.14462844  0.22915351]]\n"
     ]
    }
   ],
   "source": [
    "test_0x_label = []\n",
    "test_0y_label = []\n",
    "read_wifi_data(filename0_te,test_0x_label,test_0y_label, address_index_te)\n",
    "bc_x = np.reshape(test_0x_label,(-1,1))\n",
    "gain_0y_label = sfmax.eval({X: bc_x},sess)\n",
    "print gain_0y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3352724   0.26433083  0.16897294  0.23142378]\n",
      " [ 0.32401934  0.2555981   0.1880669   0.23231564]\n",
      " [ 0.34227747  0.26975852  0.1574413   0.23052274]\n",
      " ..., \n",
      " [ 0.34845516  0.27453932  0.14750795  0.22949752]\n",
      " [ 0.34723416  0.27359486  0.14945324  0.22971769]\n",
      " [ 0.34784558  0.27406782  0.14847802  0.22960855]]\n"
     ]
    }
   ],
   "source": [
    "test_1x_label = []\n",
    "test_1y_label = []\n",
    "read_wifi_data(filename1_te,test_1x_label,test_1y_label, address_index_te)\n",
    "bc_x = np.reshape(test_1x_label,(-1,1))\n",
    "gain_1y_label = sfmax.eval({X: bc_x},sess)\n",
    "print gain_1y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33462477  0.26382869  0.17005314  0.23149346]\n",
      " [ 0.33784503  0.26632494  0.16470551  0.23112452]\n",
      " [ 0.34164968  0.26927239  0.15846324  0.23061466]\n",
      " ..., \n",
      " [ 0.34352756  0.27072641  0.15541308  0.230333  ]\n",
      " [ 0.35027304  0.27594504  0.14462844  0.22915351]\n",
      " [ 0.35207453  0.27733755  0.14179471  0.2287932 ]]\n"
     ]
    }
   ],
   "source": [
    "test_2x_label = []\n",
    "test_2y_label = []\n",
    "read_wifi_data(filename2_te,test_2x_label,test_2y_label, address_index_te)\n",
    "bc_x = np.reshape(test_2x_label,(-1,1))\n",
    "gain_2y_label = sfmax.eval({X: bc_x},sess)\n",
    "print gain_2y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33332404  0.26282004  0.17222951  0.23162645]\n",
      " [ 0.33848366  0.26681983  0.16365194  0.23104456]\n",
      " [ 0.34414989  0.27120817  0.1544068   0.23023523]\n",
      " ..., \n",
      " [ 0.34600595  0.27264458  0.15141915  0.22993039]\n",
      " [ 0.34784558  0.27406782  0.14847802  0.22960855]\n",
      " [ 0.35027304  0.27594504  0.14462844  0.22915351]]\n"
     ]
    }
   ],
   "source": [
    "test_3x_label = []\n",
    "test_3y_label = []\n",
    "read_wifi_data(filename3_te,test_3x_label,test_3y_label, address_index_te)\n",
    "bc_x = np.reshape(test_3x_label,(-1,1))\n",
    "gain_1y_label = sfmax.eval({X: bc_x},sess)\n",
    "print gain_1y_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디스커션\n",
    "\n",
    "data set의 갯수만큼의 확률을 나타냄\n",
    "[3119, 2380, 1511, 2017] 개의 data와 nn을 통과한 data가 유사한 확률을 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이유\n",
    "\n",
    "1. 각 x_data 즉, ap signal 신호가 서로 산재해 있어서 그 신호자체만으로는 ap address dimension을 이룰수가 없음.\n",
    "         1-1. hidden dimension의 크기를 조정해봐도 아무런 효과가 없는 것으로 보아, dimension은 현재 아무런 의미가 없는 것이 확실하다.\n",
    "2. 그 상황에서 label의 비중자체가 하나의 dimension으로 자리잡게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개선방안\n",
    "\n",
    "1. 시간마다 모은 dataset을 입력으로 받아옴 (예:00:27:1c:9 = -56, 00:23:11:cc = =74)\n",
    "2. 이렇게 되면 ap address로 dimension을 분화시킬 수 있을 것이라고 생각함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 생각해 봐야할 점\n",
    "\n",
    "activation function을 relu를 썼을 때를 제외하고, tanh, sigmoid를 이용하였을 때에는 weight가 satuation이 된 것처럼 모든 sfmax set이 같은 값을 갖고 있었음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
